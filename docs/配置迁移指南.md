# 配置迁移指南

## 概述

Cognitive Razor 插件从 v2.0.0 开始进行了重要的架构调整：

- **移除独立的 OpenRouter Provider**：不再将 OpenRouter 作为单独的 Provider 类型
- **引入自定义端点功能**：允许为 OpenAI 和 Gemini Provider 配置自定义 API 端点
- **更灵活的配置方式**：支持任何兼容 OpenAI 或 Gemini API 的服务

这一变更使得插件更加灵活，用户可以轻松使用 OpenRouter、本地模型或其他第三方服务，而无需为每个服务单独开发 Provider。

## 迁移功能

### 自动迁移

当插件启动时，迁移管理器会自动检测配置版本并执行必要的迁移：

1. **检测 OpenRouter 配置**：如果检测到 OpenRouter Provider，会显示迁移向导
2. **添加默认端点**：为现有的 OpenAI 和 Gemini Provider 添加默认 baseUrl
3. **更新版本号**：将配置版本更新到 2.0.0

### OpenRouter 迁移向导

如果检测到 OpenRouter 配置，插件会显示迁移向导，提供三个选项：

#### 选项 1：迁移到 OpenAI + 自定义端点

- 将 OpenRouter 配置转换为 OpenAI Provider
- 设置自定义端点为 `https://openrouter.ai/api/v1`
- 保留原有的 API Key 和模型配置

#### 选项 2：配置新的 Provider

- 删除 OpenRouter 配置
- 引导用户配置新的 OpenAI 或 Gemini Provider

#### 选项 3：稍后处理

- 删除 OpenRouter 配置
- 用户可以稍后在设置中手动配置

## 自定义端点配置

### 支持的 Provider

从 v2.0.0 开始，插件支持两种基础 Provider：

- **OpenAI**：默认端点 `https://api.openai.com/v1`
- **Google Gemini**：默认端点 `https://generativelanguage.googleapis.com/v1beta`

### 使用自定义端点

在 Provider 配置中，可以设置自定义端点：

1. 打开插件设置 → Cognitive Razor
2. 点击"添加提供商"或编辑现有 Provider
3. 在"自定义端点"字段中输入 URL
4. 留空则使用默认端点

**URL 验证规则**：
- 必须以 `http://` 或 `https://` 开头
- 必须是有效的 URL 格式
- 建议使用 HTTPS 以确保安全性

### 兼容的第三方服务

自定义端点功能支持任何与 OpenAI 或 Gemini API 兼容的服务：

#### OpenRouter
```
Provider 类型: OpenAI
自定义端点: https://openrouter.ai/api/v1
API Key: 你的 OpenRouter API Key
模型: 任何 OpenRouter 支持的模型
```

#### 本地 Ollama
```
Provider 类型: OpenAI
自定义端点: http://localhost:11434/v1
API Key: ollama（或任意值）
模型: llama2, mistral, 等
```

#### 本地 LM Studio
```
Provider 类型: OpenAI
自定义端点: http://localhost:1234/v1
API Key: lm-studio（或任意值）
模型: 你加载的模型名称
```

#### 其他兼容服务
任何实现了 OpenAI 或 Gemini API 接口的服务都可以使用，包括：
- Azure OpenAI Service
- 私有部署的模型服务
- 其他云服务提供商的兼容 API

## 技术细节

### 迁移脚本

迁移脚本位于 `src/data/migrations.ts`，包含：

- `migrationV2`：主要迁移逻辑
- 检测 OpenRouter 配置
- 添加默认 baseUrl
- 更新版本号

### 迁移管理器

迁移管理器位于 `src/core/migration-manager.ts`，负责：

- 初始化迁移运行器
- 检查迁移需求
- 显示迁移向导
- 执行迁移操作

### 迁移向导

迁移向导位于 `src/ui/migration-wizard.ts`，提供：

- OpenRouter 迁移向导 Modal
- 通用迁移提示 Modal
- 用户友好的迁移界面

## 故障排除

### 迁移失败

如果迁移失败，请检查：

1. 日志文件中的错误信息
2. 配置文件是否损坏
3. 是否有足够的磁盘空间

### 手动迁移

如果自动迁移失败，可以手动迁移：

1. 备份配置文件（`.obsidian/plugins/obsidian-cognitive-razor/data/settings.json`）
2. 删除 OpenRouter Provider 配置
3. 为现有 Provider 添加 `baseUrl` 字段
4. 更新 `version` 字段为 `"2.0.0"`

### 回滚

如果需要回滚到旧版本：

1. 恢复备份的配置文件
2. 重新安装旧版本的插件

## 常见问题

### Q: 迁移后我的 API Key 会丢失吗？

A: 不会。迁移过程会保留所有现有的配置，包括 API Key。如果选择"迁移到 OpenAI + 自定义端点"，你的 OpenRouter API Key 会被保留并转移到新的配置中。

### Q: 我可以继续使用 OpenRouter 吗？

A: 可以。使用 OpenAI Provider + 自定义端点指向 OpenRouter 即可。配置方法：
1. 选择 OpenAI Provider
2. 输入 OpenRouter API Key
3. 设置自定义端点为 `https://openrouter.ai/api/v1`
4. 选择 OpenRouter 支持的模型

### Q: 迁移是否可逆？

A: 迁移脚本包含回滚功能，但建议在迁移前备份配置文件。如果需要回滚：
1. 恢复备份的 `settings.json` 文件
2. 重新安装旧版本的插件

### Q: 自定义端点支持哪些协议？

A: 支持 HTTP 和 HTTPS 协议。建议使用 HTTPS 以确保安全性。对于本地服务（如 Ollama），可以使用 HTTP。

### Q: 为什么要移除 OpenRouter Provider？

A: 主要原因：
1. **减少冗余代码**：OpenRouter 本质上是 OpenAI API 的代理，不需要单独实现
2. **提高灵活性**：自定义端点功能支持任何兼容服务，不仅限于 OpenRouter
3. **简化维护**：减少需要维护的 Provider 类型
4. **统一接口**：所有兼容 OpenAI API 的服务都可以使用相同的配置方式

### Q: 自定义端点会影响性能吗？

A: 不会。自定义端点只是改变了 API 请求的目标地址，不会影响性能。实际性能取决于你使用的服务。

### Q: 可以同时配置多个自定义端点吗？

A: 可以。你可以添加多个 Provider，每个 Provider 可以有不同的自定义端点。例如：
- Provider 1: OpenAI 官方 API
- Provider 2: OpenRouter（OpenAI + 自定义端点）
- Provider 3: 本地 Ollama（OpenAI + 自定义端点）

### Q: 如何验证自定义端点是否正确？

A: 在配置 Provider 时，点击"测试连接"按钮。系统会发送测试请求到自定义端点，并显示结果。如果测试失败，请检查：
- URL 格式是否正确
- 服务是否已启动
- 网络连接是否正常
- API Key 是否有效

## 使用示例

### 示例 1：从 OpenRouter 迁移

**旧配置（v1.x）**：
```json
{
  "providers": {
    "my-openrouter": {
      "type": "openrouter",
      "apiKey": "sk-or-v1-xxx",
      "defaultChatModel": "anthropic/claude-3-opus",
      "defaultEmbedModel": "openai/text-embedding-3-small",
      "enabled": true
    }
  }
}
```

**新配置（v2.0+）**：
```json
{
  "providers": {
    "my-openrouter": {
      "type": "openai",
      "apiKey": "sk-or-v1-xxx",
      "baseUrl": "https://openrouter.ai/api/v1",
      "defaultChatModel": "anthropic/claude-3-opus",
      "defaultEmbedModel": "openai/text-embedding-3-small",
      "enabled": true
    }
  }
}
```

### 示例 2：配置本地 Ollama

```json
{
  "providers": {
    "local-ollama": {
      "type": "openai",
      "apiKey": "ollama",
      "baseUrl": "http://localhost:11434/v1",
      "defaultChatModel": "llama2",
      "defaultEmbedModel": "nomic-embed-text",
      "enabled": true
    }
  }
}
```

### 示例 3：同时使用多个服务

```json
{
  "providers": {
    "official-openai": {
      "type": "openai",
      "apiKey": "sk-xxx",
      "baseUrl": "https://api.openai.com/v1",
      "defaultChatModel": "gpt-4-turbo-preview",
      "defaultEmbedModel": "text-embedding-3-small",
      "enabled": true
    },
    "openrouter": {
      "type": "openai",
      "apiKey": "sk-or-v1-xxx",
      "baseUrl": "https://openrouter.ai/api/v1",
      "defaultChatModel": "anthropic/claude-3-opus",
      "defaultEmbedModel": "openai/text-embedding-3-small",
      "enabled": true
    },
    "local-model": {
      "type": "openai",
      "apiKey": "local",
      "baseUrl": "http://localhost:11434/v1",
      "defaultChatModel": "llama2",
      "defaultEmbedModel": "nomic-embed-text",
      "enabled": false
    }
  },
  "defaultProviderId": "official-openai"
}
```

## 最佳实践

### 1. 备份配置

在进行任何配置更改前，备份配置文件：

```bash
cp <vault>/.obsidian/plugins/obsidian-cognitive-razor/data/settings.json settings.json.backup
```

### 2. 测试连接

配置新的 Provider 后，务必点击"测试连接"按钮验证配置是否正确。

### 3. 逐步迁移

如果你有多个 Provider 配置，建议逐个迁移并测试，而不是一次性全部迁移。

### 4. 保留旧配置

在确认新配置工作正常之前，保留旧版本的配置文件备份。

### 5. 查看日志

如果遇到问题，查看日志文件（`data/logs/`）了解详细错误信息。

## 更多信息

- [快速开始指南](./快速开始指南.md)
- [常见问题解答](./常见问题解答.md)
- [故障排除指南](./故障排除指南.md)

## 获取帮助

如果在迁移过程中遇到问题：

1. 查看本指南的"常见问题"部分
2. 查看[故障排除指南](./故障排除指南.md)
3. 在 [GitHub Issues](https://github.com/your-username/obsidian-cognitive-razor/issues) 搜索相关问题
4. 在 [讨论区](https://github.com/your-username/obsidian-cognitive-razor/discussions) 提问
